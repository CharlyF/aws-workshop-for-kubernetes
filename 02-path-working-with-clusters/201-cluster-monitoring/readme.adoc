= Kubernetes Cluster Monitoring
:toc:
:icons:
:linkcss:
:imagesdir: ../../resources/images

== Introduction

This chapter will demonstrate how to monitor a Kubernetes cluster using the following:

. Datadog
. Full stack application in python with MongoDB, Redis, NGINX.

Datadog is a monitoring service for cloud-scale applications, providing monitoring of servers, databases, tools, and services, through a SaaS-based data analytics platform.
It gives a unified view of an entire stack, allowing to seamlessly monitor metrics, application traces as well as logs.



== Prerequisites

In order to perform exercises in this chapter, you'll need to deploy configurations to an EKS cluster.  To create an EKS cluster, use the link:../../01-path-basics/102-your-first-cluster#create-a-kubernetes-cluster-with-eks[AWS CLI] (recommended), or alternatively, link:../../01-path-basics/102-your-first-cluster#alternative-create-a-kubernetes-cluster-with-kops[kops].

All configuration files for this chapter are in the link:templates[201-cluster-monitoring/templates] directory.

== Getting Started with Datadog

=== Collecting Data

Monitoring starts by collecting data, so we can first start by taking a look at [the integration page](https://app.datadoghq.com/account/settings). On this page you can see the list of technologies Datadog integrates with.
From cloud providers like AWS, Google Cloud or Azure to tools like chef, puppet or ansible including all the different technos from each layer of the application stack.
Databases like Postegres, Mysql. Webservers like NGINX, HAProxy and so on and so forth.

Today, we will be using:
- Kubernetes
- Docker
- NGINX
- MongoDB
- Redis
- Python

There are multiple ways to collect data - The first one is via our https://github.com/DataDog/datadog-agent[agent].
We will deploy the agent on all the nodes of our EKS cluster. It will run as a pod, along side our application.

Another option is with the Datadog API, and lastly, using our crawler based integration such as AWS, GCP...

=== Data sources

Datadog is capable to collect metrics, application traces as well as logs.
Throughout the UI, you will be able to go back and forth between the three of them.
You can refer to the specific documentation of each:

- https://docs.datadoghq.com/developers/metrics/[Metrics]
- https://docs.datadoghq.com/tracing/[Tracing]
- https://docs.datadoghq.com/logs/[Logs]

In this workshop we will be playing with all of them.

=== Visualizing Data

Start by logging into your Datadog account at https://app.datadoghq.com.
On the navigation bar, located on the left of your screen, you should be able to see different items, that we will be using later on.
First of all, the Dashboard section:

image::datadogdashboards.png[]

Dashboards are used to visualize and correlate metrics, traces or logs.
As you enable an integration (i.e. configure your agents to report data from Postgres or configure the AWS integration) out of the box dashboards will be created for you.
You can also create your custom dashboards, they are highly flexible.

image::coffeehouse.png[]

=== Monitoring Data

The last part is monitoring.
On the [monitoring page](https://app.datadoghq.com/monitors#/create), you will be welcomed with a number of options depending on what you want to monitor.

In the following screenshot you can see that we are creating a monitor for logs. Specifying the source, the status and the count of logs to trigger the alert.

image::logmonitor.png[]


== Workshop

=== Monitoring

The goal of this workshop is to set up a full stack application on EKS and see how each layer of the stack can be monitored with the agent.

Start by taking a look at the link:../201-cluster-monitoring/templates/datadog/agent.yaml[manifest to run the agent].
Insert a Datadog API Key that can be found in your https://app.datadoghq.com/account/settings#api[Datadog account] in the `value: <DD_API_KEY>` placeholder.

Then from the current directory, just run:

  $ kubectl apply -f templates/datadog/agent.yaml

TODO add output

As this manifest is a DaemonSet, this will deploy an agent on all your nodes. The agent will live inside a pod.

=== The Database

From the https://kubernetes.io/blog/2017/01/running-mongodb-on-kubernetes-with-statefulsets/[Kubernetes Blog] on deploying a MongoDB StatefulSet on Kubernetes:
To set up the MongoDB replica set, you need three things: A StorageClass, a Headless Service, and a StatefulSet.
We will start by creating a StorageClass to tell Kubernetes what kind of storage to use for the database nodes.
In this case, we will rely on EBS GP2s to store our data.

  $ kubectl apply -f templates/mongodb/storageclass.yaml

TODO add output

Once the storage is ready, we can spin up our MongoDB with 3 replicas.

  $ kubectl apply -f templates/mongodb/mongo.yaml

TODO add output

Note that this will create a service which will operate as a headless loadbalancer in front of the DBs.
This will also generate Persistent Volume Claims, these should appear as EBS volumes in your AWS account.

Finally, for the sake of monitoring, we are going to create a user in the Primary, which will be used by the agent to collect data.

You can run the following command:

  $ kubectl exec -it mongo-1 -- sh -c 'mongo admin --host localhost --eval "db.createUser({ user: \"datadog\", pwd: \"tndPhL3wrMEDuj4wLEHmbxbV\", roles: [ {role: \"read\", db: \"admin\"}, {role: \"clusterMonitor\", db:\"admin\"},{role: \"read\", db: \"local\" } ] });"'

=== The cache

We will be leveraging Redis to cache data.
TODO more details about Redis

You can run

 $ kubectl apply -f templates/redis/redis.yaml

Which will create a redis pod and a headless service in front of it

=== Deploy the application

Now is time to deploy your application.

 $ kubectl apply -f templates/webapp/webapp.yaml

This will create a pod running the application as well as a service in front of it.

This webapp is an interface to spin up scenarii, where different parts of the stack are stimulated and the impact of each expecrience can be visualized in the Datadog app.

=== Exposing your app

Now is time to see the result of your labor.

Spin up the nginx manifest, this will create a webserver that will front the application as well as a service.
The service, as opposed to the above services is configured to be a LoadBalancer. Therefore, it will spin up an ELB and will make a public DNS that will be exposed to the world.

 $ kubectl apply -f templates/nginx/nginx.yaml

This will also create a ConfigMap used to store the nginx config as an ETCD object instead of a physical file. The benefit is that the file does not have to be present on each node.

Now, take a look at your LoadBalancer being configured:

 $ kubectl describe svc nginx-deployment

```
Name:                     nginx-deployment
Namespace:                default
Labels:                   <none>
Annotations:              kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"nginx-deployment","namespace":"default"},"spec":{"ports":[{"name":"nginx","por...
Selector:                 role=nginx
Type:                     LoadBalancer
IP:                       10.100.29.226
LoadBalancer Ingress:     a973c485a832811e8b84c06bfcd83c35-831258848.us-west-2.elb.amazonaws.com
Port:                     nginx  80/TCP
TargetPort:               80/TCP
NodePort:                 nginx  31675/TCP
Endpoints:                192.168.159.101:80,192.168.197.28:80,192.168.70.107:80
Session Affinity:         None
External Traffic Policy:  Cluster
Events:
  Type    Reason                Age   From                Message
  ----    ------                ----  ----                -------
  Normal  EnsuringLoadBalancer  22m   service-controller  Ensuring load balancer
  Normal  EnsuredLoadBalancer   22m   service-controller  Ensured load balancer
```

Going to the Load Balancer Ingress indicated should show the following page:

image::webapp.png[]


== Monitoring

=== Metrics

Open the host map, go to the container map
You can open the container live view

Then, go the the redis dashboard and mongo db ?

The agent is collecting the metrics from these via the Autodiscovery process.
It works with Annotations in this case.


=== Logs

Let's stress the cache of our app and see the logs.

Go on to the redis metric that surges, click to see the related logs.
We can also see logs about mongo, redis, the app.

=== Traces

Now, let's run the infinite demo.
from the logs, let's look at the traces.

At this point, you can stop the infinite demo.

We recommend letting the agents up, as the next steps of the workshop will also have a monitoring section.

=== Setting up some monitors

* Monitoring the Infrastructure

* Monitoring the DB

* Monitoring the cache

* Monitoring the Webserver

* Monitoring the app (with traces and logs)

== Going Further

Create DCA ?


At this point,
=== Cleanup

Remove all the installed components:

    kubectl delete -f templates/datadog
    kubectl delete -f templates/mongo
    kubectl delete -f templates/redis
    kubectl delete -f templates/nginx
    kubectl delete -f templates/webapp

    kubectl get pvc
    kubectl delete pvc-*

You are now ready to continue on with the workshop!

:frame: none
:grid: none
:valign: top

[align="center", cols="2", grid="none", frame="none"]
|=====
|image:button-continue-standard.png[link=../../02-path-working-with-clusters/202-service-mesh]
|image:button-continue-operations.png[link=../../02-path-working-with-clusters/202-service-mesh]
|link:../../standard-path.adoc[Go to Standard Index]
|link:../../operations-path.adoc[Go to Operations Index]
|=====
